<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>21 Week 12 Lecture | Bayesian Data Analysis and Computation Lecture and Lab Notes</title>
  <meta name="description" content="21 Week 12 Lecture | Bayesian Data Analysis and Computation Lecture and Lab Notes" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="21 Week 12 Lecture | Bayesian Data Analysis and Computation Lecture and Lab Notes" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="21 Week 12 Lecture | Bayesian Data Analysis and Computation Lecture and Lab Notes" />
  
  
  

<meta name="author" content="Heather Lynch" />


<meta name="date" content="2020-11-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="week-11-lab.html"/>
<link rel="next" href="week-12-lab.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Data Analysis and Computation Lecture and Lab Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="week-1-lecture.html"><a href="week-1-lecture.html"><i class="fa fa-check"></i><b>1</b> Week 1 Lecture</a><ul>
<li class="chapter" data-level="1.1" data-path="week-1-lecture.html"><a href="week-1-lecture.html#introduction-to-this-course"><i class="fa fa-check"></i><b>1.1</b> Introduction to this course</a></li>
<li class="chapter" data-level="1.2" data-path="week-1-lecture.html"><a href="week-1-lecture.html#some-probability-vocabulary"><i class="fa fa-check"></i><b>1.2</b> Some probability vocabulary</a></li>
<li class="chapter" data-level="1.3" data-path="week-1-lecture.html"><a href="week-1-lecture.html#statistical-philosophy-and-the-foundations-of-bayesian-analysis"><i class="fa fa-check"></i><b>1.3</b> Statistical philosophy and the foundations of Bayesian analysis</a></li>
<li class="chapter" data-level="1.4" data-path="week-1-lecture.html"><a href="week-1-lecture.html#testing-jags-installation"><i class="fa fa-check"></i><b>1.4</b> Testing JAGS installation</a></li>
<li class="chapter" data-level="1.5" data-path="week-1-lecture.html"><a href="week-1-lecture.html#for-more-information-about-this-weeks-topic"><i class="fa fa-check"></i><b>1.5</b> For more information about this week's topic</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="week-1-lab.html"><a href="week-1-lab.html"><i class="fa fa-check"></i><b>2</b> Week 1 Lab</a></li>
<li class="chapter" data-level="3" data-path="week-2-lecture.html"><a href="week-2-lecture.html"><i class="fa fa-check"></i><b>3</b> Week 2 Lecture</a><ul>
<li class="chapter" data-level="3.1" data-path="week-2-lecture.html"><a href="week-2-lecture.html#bayes-theorem-and-all-that-follows-from-it"><i class="fa fa-check"></i><b>3.1</b> Bayes Theorem and all that follows from it</a></li>
<li class="chapter" data-level="3.2" data-path="week-2-lecture.html"><a href="week-2-lecture.html#how-do-we-interpret-the-posteriors"><i class="fa fa-check"></i><b>3.2</b> How do we interpret the posteriors?</a></li>
<li class="chapter" data-level="3.3" data-path="week-2-lecture.html"><a href="week-2-lecture.html#a-slight-detour-to-get-us-thinking-about-the-basic-philosophy-behind-bayesian-stats"><i class="fa fa-check"></i><b>3.3</b> A slight detour, to get us thinking about the basic philosophy behind Bayesian stats</a></li>
<li class="chapter" data-level="3.4" data-path="week-2-lecture.html"><a href="week-2-lecture.html#getting-some-more-practice-with-jags"><i class="fa fa-check"></i><b>3.4</b> Getting some more practice with JAGS</a></li>
<li class="chapter" data-level="3.5" data-path="week-1-lecture.html"><a href="week-1-lecture.html#for-more-information-about-this-weeks-topic"><i class="fa fa-check"></i><b>3.5</b> For more information about this week's topic</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="week-3-lecture.html"><a href="week-3-lecture.html"><i class="fa fa-check"></i><b>4</b> Week 3 Lecture</a><ul>
<li class="chapter" data-level="4.1" data-path="week-3-lecture.html"><a href="week-3-lecture.html#how-do-we-obtain-priors"><i class="fa fa-check"></i><b>4.1</b> How do we obtain priors?</a><ul>
<li class="chapter" data-level="4.1.1" data-path="week-3-lecture.html"><a href="week-3-lecture.html#published-literature-as-a-source-of-prior-information"><i class="fa fa-check"></i><b>4.1.1</b> Published literature as a source of prior information</a></li>
<li class="chapter" data-level="4.1.2" data-path="week-3-lecture.html"><a href="week-3-lecture.html#expert-opinion"><i class="fa fa-check"></i><b>4.1.2</b> Expert opinion</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="week-3-lecture.html"><a href="week-3-lecture.html#conjugacy"><i class="fa fa-check"></i><b>4.2</b> Conjugacy</a></li>
<li class="chapter" data-level="4.3" data-path="week-3-lecture.html"><a href="week-3-lecture.html#sensitivity-analysis"><i class="fa fa-check"></i><b>4.3</b> Sensitivity analysis</a></li>
<li class="chapter" data-level="4.4" data-path="week-1-lecture.html"><a href="week-1-lecture.html#for-more-information-about-this-weeks-topic"><i class="fa fa-check"></i><b>4.4</b> For more information about this week's topic</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="week-3-lab.html"><a href="week-3-lab.html"><i class="fa fa-check"></i><b>5</b> Week 3 Lab</a><ul>
<li class="chapter" data-level="5.1" data-path="week-3-lab.html"><a href="week-3-lab.html#congugacy"><i class="fa fa-check"></i><b>5.1</b> Congugacy</a></li>
<li class="chapter" data-level="5.2" data-path="week-3-lab.html"><a href="week-3-lab.html#moment-matching-two-distributions"><i class="fa fa-check"></i><b>5.2</b> Moment Matching two distributions</a></li>
<li class="chapter" data-level="5.3" data-path="week-3-lab.html"><a href="week-3-lab.html#from-prior-to-posterior-to-prior"><i class="fa fa-check"></i><b>5.3</b> From Prior to Posterior to Prior</a></li>
<li class="chapter" data-level="5.4" data-path="week-3-lab.html"><a href="week-3-lab.html#adding-data-one-at-a-time-or-all-at-once"><i class="fa fa-check"></i><b>5.4</b> Adding data: One at a time or all at once?</a></li>
<li class="chapter" data-level="5.5" data-path="week-3-lab.html"><a href="week-3-lab.html#what-impact-did-the-choice-of-prior-have"><i class="fa fa-check"></i><b>5.5</b> What impact did the choice of prior have?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="week-4-lecture.html"><a href="week-4-lecture.html"><i class="fa fa-check"></i><b>6</b> Week 4 Lecture</a><ul>
<li class="chapter" data-level="6.1" data-path="week-4-lecture.html"><a href="week-4-lecture.html#conjugacy-aside-how-to-actually-calculate-the-posterior"><i class="fa fa-check"></i><b>6.1</b> Conjugacy aside, how to actually calculate the posterior</a></li>
<li class="chapter" data-level="6.2" data-path="week-4-lecture.html"><a href="week-4-lecture.html#monte-carlo-methods"><i class="fa fa-check"></i><b>6.2</b> Monte Carlo Methods</a></li>
<li class="chapter" data-level="6.3" data-path="week-4-lecture.html"><a href="week-4-lecture.html#rejection-sampling"><i class="fa fa-check"></i><b>6.3</b> Rejection Sampling</a></li>
<li class="chapter" data-level="6.4" data-path="week-4-lecture.html"><a href="week-4-lecture.html#adaptive-rejection-sampling"><i class="fa fa-check"></i><b>6.4</b> Adaptive Rejection Sampling</a></li>
<li class="chapter" data-level="6.5" data-path="week-4-lecture.html"><a href="week-4-lecture.html#monte-carlo-integration"><i class="fa fa-check"></i><b>6.5</b> Monte Carlo Integration</a></li>
<li class="chapter" data-level="6.6" data-path="week-4-lecture.html"><a href="week-4-lecture.html#sometimes-you-just-want-the-integral..."><i class="fa fa-check"></i><b>6.6</b> Sometimes you just want the integral...</a></li>
<li class="chapter" data-level="6.7" data-path="week-4-lecture.html"><a href="week-4-lecture.html#importance-sampling"><i class="fa fa-check"></i><b>6.7</b> Importance Sampling</a></li>
<li class="chapter" data-level="6.8" data-path="week-4-lecture.html"><a href="week-4-lecture.html#sampling-importance-resampling"><i class="fa fa-check"></i><b>6.8</b> Sampling Importance Resampling</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="week-4-lab.html"><a href="week-4-lab.html"><i class="fa fa-check"></i><b>7</b> Week 4 Lab</a><ul>
<li class="chapter" data-level="7.1" data-path="week-4-lab.html"><a href="week-4-lab.html#smith-and-gelfand-1992"><i class="fa fa-check"></i><b>7.1</b> Smith and Gelfand (1992)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="week-5-lecture.html"><a href="week-5-lecture.html"><i class="fa fa-check"></i><b>8</b> Week 5 Lecture</a><ul>
<li class="chapter" data-level="8.1" data-path="week-5-lecture.html"><a href="week-5-lecture.html#gibbs-sampling"><i class="fa fa-check"></i><b>8.1</b> Gibbs Sampling</a></li>
<li class="chapter" data-level="8.2" data-path="week-5-lecture.html"><a href="week-5-lecture.html#metropolis-algorithm"><i class="fa fa-check"></i><b>8.2</b> Metropolis algorithm</a></li>
<li class="chapter" data-level="8.3" data-path="week-5-lecture.html"><a href="week-5-lecture.html#the-messy-reality-hybrid-of-m-h-and-gibbs"><i class="fa fa-check"></i><b>8.3</b> The Messy reality = Hybrid of M-H and Gibbs</a></li>
<li class="chapter" data-level="8.4" data-path="week-5-lecture.html"><a href="week-5-lecture.html#convergence"><i class="fa fa-check"></i><b>8.4</b> Convergence</a></li>
<li class="chapter" data-level="8.5" data-path="week-5-lecture.html"><a href="week-5-lecture.html#bayesian-change-point-example"><i class="fa fa-check"></i><b>8.5</b> Bayesian change point example</a></li>
<li class="chapter" data-level="8.6" data-path="week-5-lecture.html"><a href="week-5-lecture.html#hierarchical-model"><i class="fa fa-check"></i><b>8.6</b> Hierarchical model</a></li>
<li class="chapter" data-level="8.7" data-path="week-1-lecture.html"><a href="week-1-lecture.html#for-more-information-about-this-weeks-topic"><i class="fa fa-check"></i><b>8.7</b> For more information about this week's topic</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="week-5-lab.html"><a href="week-5-lab.html"><i class="fa fa-check"></i><b>9</b> Week 5 Lab</a><ul>
<li class="chapter" data-level="9.1" data-path="week-5-lab.html"><a href="week-5-lab.html#gibbs-sampler"><i class="fa fa-check"></i><b>9.1</b> Gibbs Sampler</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="week-6-lab.html"><a href="week-6-lab.html"><i class="fa fa-check"></i><b>10</b> Week 6 Lab</a><ul>
<li class="chapter" data-level="10.1" data-path="week-6-lab.html"><a href="week-6-lab.html#fitting-a-distribution"><i class="fa fa-check"></i><b>10.1</b> Fitting a distribution</a></li>
<li class="chapter" data-level="10.2" data-path="week-6-lab.html"><a href="week-6-lab.html#one-way-anova"><i class="fa fa-check"></i><b>10.2</b> One-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="week-7-lecture.html"><a href="week-7-lecture.html"><i class="fa fa-check"></i><b>11</b> Week 7 Lecture</a><ul>
<li class="chapter" data-level="11.1" data-path="week-7-lecture.html"><a href="week-7-lecture.html#an-exercise-with-regression"><i class="fa fa-check"></i><b>11.1</b> An exercise with regression</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="week-7-lab.html"><a href="week-7-lab.html"><i class="fa fa-check"></i><b>12</b> Week 7 Lab</a><ul>
<li class="chapter" data-level="12.1" data-path="week-7-lab.html"><a href="week-7-lab.html#class-projects"><i class="fa fa-check"></i><b>12.1</b> Class projects</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="week-8-lecture.html"><a href="week-8-lecture.html"><i class="fa fa-check"></i><b>13</b> Week 8 Lecture</a></li>
<li class="chapter" data-level="14" data-path="week-8-lab.html"><a href="week-8-lab.html"><i class="fa fa-check"></i><b>14</b> Week 8 Lab</a></li>
<li class="chapter" data-level="15" data-path="week-9-lecture.html"><a href="week-9-lecture.html"><i class="fa fa-check"></i><b>15</b> Week 9 Lecture</a><ul>
<li class="chapter" data-level="15.1" data-path="week-9-lecture.html"><a href="week-9-lecture.html#the-probability-of-estimability"><i class="fa fa-check"></i><b>15.1</b> The probability of estimability</a></li>
<li class="chapter" data-level="15.2" data-path="week-9-lecture.html"><a href="week-9-lecture.html#multilevel-modelling-ala-gelman-and-hill"><i class="fa fa-check"></i><b>15.2</b> Multilevel modelling ala Gelman and Hill</a></li>
<li class="chapter" data-level="15.3" data-path="week-9-lecture.html"><a href="week-9-lecture.html#in-sum...."><i class="fa fa-check"></i><b>15.3</b> In sum....</a></li>
<li class="chapter" data-level="15.4" data-path="week-9-lecture.html"><a href="week-9-lecture.html#nice-et-al.-2014"><i class="fa fa-check"></i><b>15.4</b> Nice et al. (2014)</a></li>
<li class="chapter" data-level="15.5" data-path="week-1-lecture.html"><a href="week-1-lecture.html#for-more-information-about-this-weeks-topic"><i class="fa fa-check"></i><b>15.5</b> For more information about this week's topic</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="week-9-lab.html"><a href="week-9-lab.html"><i class="fa fa-check"></i><b>16</b> Week 9 Lab</a></li>
<li class="chapter" data-level="17" data-path="week-10-lecture.html"><a href="week-10-lecture.html"><i class="fa fa-check"></i><b>17</b> Week 10 Lecture</a><ul>
<li class="chapter" data-level="17.1" data-path="week-5-lecture.html"><a href="week-5-lecture.html#convergence"><i class="fa fa-check"></i><b>17.1</b> Convergence</a></li>
<li class="chapter" data-level="17.2" data-path="week-10-lecture.html"><a href="week-10-lecture.html#testing-for-convergence"><i class="fa fa-check"></i><b>17.2</b> Testing for convergence</a></li>
<li class="chapter" data-level="17.3" data-path="week-10-lecture.html"><a href="week-10-lecture.html#gelman-rubin-statistic"><i class="fa fa-check"></i><b>17.3</b> Gelman-Rubin statistic</a></li>
<li class="chapter" data-level="17.4" data-path="week-10-lecture.html"><a href="week-10-lecture.html#the-take-away-what-should-we-be-checking-after-we-run-our-models"><i class="fa fa-check"></i><b>17.4</b> The take away: What should we be checking after we run our models</a></li>
<li class="chapter" data-level="17.5" data-path="week-10-lecture.html"><a href="week-10-lecture.html#missing-data"><i class="fa fa-check"></i><b>17.5</b> Missing data</a></li>
<li class="chapter" data-level="17.6" data-path="week-10-lecture.html"><a href="week-10-lecture.html#initial-values"><i class="fa fa-check"></i><b>17.6</b> Initial values</a></li>
<li class="chapter" data-level="17.7" data-path="week-10-lecture.html"><a href="week-10-lecture.html#sample-scripts-and-output-for-prior-posterior-overlap"><i class="fa fa-check"></i><b>17.7</b> Sample scripts and output for prior-posterior overlap</a></li>
<li class="chapter" data-level="17.8" data-path="week-1-lecture.html"><a href="week-1-lecture.html#for-more-information-about-this-weeks-topic"><i class="fa fa-check"></i><b>17.8</b> For more information about this week's topic</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="week-10-lab.html"><a href="week-10-lab.html"><i class="fa fa-check"></i><b>18</b> Week 10 Lab</a></li>
<li class="chapter" data-level="19" data-path="week-11-lecture.html"><a href="week-11-lecture.html"><i class="fa fa-check"></i><b>19</b> Week 11 Lecture</a><ul>
<li class="chapter" data-level="19.1" data-path="week-11-lecture.html"><a href="week-11-lecture.html#dynamical-time-series-models"><i class="fa fa-check"></i><b>19.1</b> Dynamical (time series) models</a></li>
<li class="chapter" data-level="19.2" data-path="week-11-lecture.html"><a href="week-11-lecture.html#process-error"><i class="fa fa-check"></i><b>19.2</b> Process error</a></li>
<li class="chapter" data-level="19.3" data-path="week-11-lecture.html"><a href="week-11-lecture.html#observation-error"><i class="fa fa-check"></i><b>19.3</b> Observation error</a></li>
<li class="chapter" data-level="19.4" data-path="week-11-lecture.html"><a href="week-11-lecture.html#other-kinds-of-state-space-models"><i class="fa fa-check"></i><b>19.4</b> Other kinds of state-space models</a></li>
<li class="chapter" data-level="19.5" data-path="week-10-lecture.html"><a href="week-10-lecture.html#missing-data"><i class="fa fa-check"></i><b>19.5</b> Missing data</a></li>
<li class="chapter" data-level="19.6" data-path="week-1-lecture.html"><a href="week-1-lecture.html#for-more-information-about-this-weeks-topic"><i class="fa fa-check"></i><b>19.6</b> For more information about this week's topic</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="week-11-lab.html"><a href="week-11-lab.html"><i class="fa fa-check"></i><b>20</b> Week 11 Lab</a><ul>
<li class="chapter" data-level="20.1" data-path="week-11-lab.html"><a href="week-11-lab.html#simple-logistic"><i class="fa fa-check"></i><b>20.1</b> Simple logistic</a></li>
<li class="chapter" data-level="20.2" data-path="week-11-lab.html"><a href="week-11-lab.html#observation-error-only-model"><i class="fa fa-check"></i><b>20.2</b> Observation-error-only model</a></li>
<li class="chapter" data-level="20.3" data-path="week-11-lab.html"><a href="week-11-lab.html#process-error-only-model"><i class="fa fa-check"></i><b>20.3</b> Process-error-only model</a></li>
<li class="chapter" data-level="20.4" data-path="week-11-lab.html"><a href="week-11-lab.html#process-error-and-observation-error-together"><i class="fa fa-check"></i><b>20.4</b> Process-error and observation-error together</a></li>
<li class="chapter" data-level="20.5" data-path="week-11-lab.html"><a href="week-11-lab.html#final-thoughts"><i class="fa fa-check"></i><b>20.5</b> Final thoughts</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="week-12-lecture.html"><a href="week-12-lecture.html"><i class="fa fa-check"></i><b>21</b> Week 12 Lecture</a><ul>
<li class="chapter" data-level="21.1" data-path="week-12-lecture.html"><a href="week-12-lecture.html#mark-recapture-modeling"><i class="fa fa-check"></i><b>21.1</b> Mark-recapture modeling</a></li>
<li class="chapter" data-level="21.2" data-path="week-12-lecture.html"><a href="week-12-lecture.html#cormack-jolly-seber"><i class="fa fa-check"></i><b>21.2</b> Cormack-Jolly-Seber</a></li>
<li class="chapter" data-level="21.3" data-path="week-12-lecture.html"><a href="week-12-lecture.html#method-1-brute-force"><i class="fa fa-check"></i><b>21.3</b> Method #1: Brute force</a></li>
<li class="chapter" data-level="21.4" data-path="week-12-lecture.html"><a href="week-12-lecture.html#method-2-modeling-the-entire-capture-history"><i class="fa fa-check"></i><b>21.4</b> Method #2: Modeling the entire capture history</a></li>
<li class="chapter" data-level="21.5" data-path="week-12-lecture.html"><a href="week-12-lecture.html#what-other-kind-of-models-might-you-fit"><i class="fa fa-check"></i><b>21.5</b> What other kind of models might you fit</a></li>
<li class="chapter" data-level="21.6" data-path="week-12-lecture.html"><a href="week-12-lecture.html#occupancy-modelling"><i class="fa fa-check"></i><b>21.6</b> Occupancy modelling</a></li>
<li class="chapter" data-level="21.7" data-path="week-12-lecture.html"><a href="week-12-lecture.html#dynamic-state-space-models-for-meta-population-dynamics"><i class="fa fa-check"></i><b>21.7</b> Dynamic state-space models for meta-population dynamics</a></li>
<li class="chapter" data-level="21.8" data-path="week-1-lecture.html"><a href="week-1-lecture.html#for-more-information-about-this-weeks-topic"><i class="fa fa-check"></i><b>21.8</b> For more information about this week's topic</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="week-12-lab.html"><a href="week-12-lab.html"><i class="fa fa-check"></i><b>22</b> Week 12 Lab</a><ul>
<li class="chapter" data-level="22.1" data-path="week-12-lab.html"><a href="week-12-lab.html#the-zeros-trick"><i class="fa fa-check"></i><b>22.1</b> The 'zeros' trick</a></li>
<li class="chapter" data-level="22.2" data-path="week-12-lab.html"><a href="week-12-lab.html#the-ones-trick"><i class="fa fa-check"></i><b>22.2</b> The 'ones' trick</a></li>
<li class="chapter" data-level="22.3" data-path="week-10-lecture.html"><a href="week-10-lecture.html#initial-values"><i class="fa fa-check"></i><b>22.3</b> Initial values</a></li>
<li class="chapter" data-level="22.4" data-path="week-12-lab.html"><a href="week-12-lab.html#first-a-warm-up"><i class="fa fa-check"></i><b>22.4</b> First, a warm up</a></li>
<li class="chapter" data-level="22.5" data-path="week-12-lab.html"><a href="week-12-lab.html#fitting-mark-recapture-models"><i class="fa fa-check"></i><b>22.5</b> Fitting mark-recapture models</a></li>
<li class="chapter" data-level="22.6" data-path="week-12-lab.html"><a href="week-12-lab.html#faq"><i class="fa fa-check"></i><b>22.6</b> FAQ</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="week-13-lecture.html"><a href="week-13-lecture.html"><i class="fa fa-check"></i><b>23</b> Week 13 Lecture</a><ul>
<li class="chapter" data-level="23.1" data-path="week-13-lecture.html"><a href="week-13-lecture.html#a-side-note-about-summary-statistics-the-mona-lisa"><i class="fa fa-check"></i><b>23.1</b> A side note about summary statistics: The Mona Lisa</a></li>
<li class="chapter" data-level="23.2" data-path="week-13-lecture.html"><a href="week-13-lecture.html#rejection-abc"><i class="fa fa-check"></i><b>23.2</b> Rejection ABC</a></li>
<li class="chapter" data-level="23.3" data-path="week-13-lecture.html"><a href="week-13-lecture.html#option-1-basic-rejection-abc"><i class="fa fa-check"></i><b>23.3</b> Option #1: Basic rejection ABC</a></li>
<li class="chapter" data-level="23.4" data-path="week-13-lecture.html"><a href="week-13-lecture.html#option-2-markov-chain-monte-carlo-abc"><i class="fa fa-check"></i><b>23.4</b> Option #2: Markov Chain Monte Carlo ABC</a></li>
<li class="chapter" data-level="23.5" data-path="week-13-lecture.html"><a href="week-13-lecture.html#option-3-sequential-monte-carlo-abc"><i class="fa fa-check"></i><b>23.5</b> Option #3: Sequential Monte Carlo ABC</a></li>
<li class="chapter" data-level="23.6" data-path="week-13-lecture.html"><a href="week-13-lecture.html#drawbacks-to-abc"><i class="fa fa-check"></i><b>23.6</b> Drawbacks to ABC</a></li>
<li class="chapter" data-level="23.7" data-path="week-1-lecture.html"><a href="week-1-lecture.html#for-more-information-about-this-weeks-topic"><i class="fa fa-check"></i><b>23.7</b> For more information about this week's topic</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="week-13-lab.html"><a href="week-13-lab.html"><i class="fa fa-check"></i><b>24</b> Week 13 Lab</a></li>
<li class="chapter" data-level="25" data-path="week-14-lecture.html"><a href="week-14-lecture.html"><i class="fa fa-check"></i><b>25</b> Week 14 Lecture</a><ul>
<li class="chapter" data-level="25.1" data-path="week-1-lecture.html"><a href="week-1-lecture.html#for-more-information-about-this-weeks-topic"><i class="fa fa-check"></i><b>25.1</b> For more information about this week's topic</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="week-14-lab.html"><a href="week-14-lab.html"><i class="fa fa-check"></i><b>26</b> Week 14 Lab</a></li>
<li class="chapter" data-level="27" data-path="week-15-lecture.html"><a href="week-15-lecture.html"><i class="fa fa-check"></i><b>27</b> Week 15 Lecture</a><ul>
<li class="chapter" data-level="27.1" data-path="week-15-lecture.html"><a href="week-15-lecture.html#a-quick-step-back-what-are-the-goals-of-model-selection"><i class="fa fa-check"></i><b>27.1</b> A quick step back: What are the goals of model selection?</a></li>
<li class="chapter" data-level="27.2" data-path="week-15-lecture.html"><a href="week-15-lecture.html#bayesian-model-averaging"><i class="fa fa-check"></i><b>27.2</b> Bayesian model averaging</a></li>
<li class="chapter" data-level="27.3" data-path="week-15-lecture.html"><a href="week-15-lecture.html#beyond-bayes-factors"><i class="fa fa-check"></i><b>27.3</b> Beyond Bayes Factors</a></li>
<li class="chapter" data-level="27.4" data-path="week-15-lecture.html"><a href="week-15-lecture.html#variable-selection-for-nested-models"><i class="fa fa-check"></i><b>27.4</b> Variable selection for nested models</a></li>
<li class="chapter" data-level="27.5" data-path="week-15-lecture.html"><a href="week-15-lecture.html#prior-data-conflict"><i class="fa fa-check"></i><b>27.5</b> Prior-data conflict</a></li>
<li class="chapter" data-level="27.6" data-path="week-1-lecture.html"><a href="week-1-lecture.html#for-more-information-about-this-weeks-topic"><i class="fa fa-check"></i><b>27.6</b> For more information about this week's topic</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Data Analysis and Computation Lecture and Lab Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="week-12-lecture" class="section level1">
<h1><span class="header-section-number">21</span> Week 12 Lecture</h1>
<p>Papers to read this week:</p>
<ul>
<li><a href="https://github.com/hlynch/Bayesian2020/tree/master/_data/McCarthyMasters2005.pdf">McCarthy and Masters 2005</a>: We will be using this dataset for the lab and problem set</li>
<li><a href="https://github.com/hlynch/Bayesian2020/tree/master/_data/RoyleKery2007.pdf">Royle and Kery 2007</a></li>
<li><a href="https://github.com/hlynch/Bayesian2020/tree/master/_data/RotellaNotesOnCJS.pdf">Rotella Notes on CJS models</a></li>
<li><a href="https://github.com/hlynch/Bayesian2020/tree/master/_data/GimenezEtAl2009.pdf">Gimenez et al. 2009</a>: This paper seems a bit outdated because its using WinBUGS rather than JAGS but the description of methods in this paper are quite clear and worth reading.</li>
</ul>
<p>Today we are going to cover two types of models, mark-recapture models and occupancy models that have very different applications but share the same underlying principles.</p>
<div id="mark-recapture-modeling" class="section level2">
<h2><span class="header-section-number">21.1</span> Mark-recapture modeling</h2>
<p>The basic idea behind mark-recapture is as follows: You catch an animal (hopefully lots of animals). You mark it. You come back at a later date and catch more animals. Some of these are animals with tags. Of those animals not recaptured, you do not know whether they are alive and present at the site but evaded capture, whether they died in the period between mark and recapture, or whether they survived but emigrated to another location. <strong>Mark-recapture techniques at one site (absent strict site fidelity) cannot distinguish between permanent emigration and death</strong>, and so we usually use the phrase  to reflect the fact that some of the missing animals simply moved to another location. That said, repeated recapture events allow you to estimate how many individuals that remained at the site were simply not recaptured. (For example, if the capture history looks like 1001, you know the animal didn’t die, and you can estimate the probability of recapture conditional on presence.)</p>
<p>MARK is a very popular software for mark-recapture models that uses maximum likelihood. Since this is a Bayesian class, we will stick to Bayesian solutions to the classic mark-recapture problem.</p>
</div>
<div id="cormack-jolly-seber" class="section level2">
<h2><span class="header-section-number">21.2</span> Cormack-Jolly-Seber</h2>
<p>The CJS model assumes <strong>time dependent survival</strong> and <strong>capture-specific detection probabilities</strong>. (These are different because while an animal has to survive every year, detection or non-detection only occurs when there is an effort to recapture or re-sight animals. Thus, you may have a 10 year time series in which 4 recapture surveys were completed. You would, in the most general model then, have 9 probabilities for survival to estimate (<span class="math inline">\(\phi\)</span>), but only 4 probabilities for detection (<span class="math inline">\(p\)</span>).)</p>
<p>Let’s say we have a 7 year time series, and we make an effort to re-sight animals in each year. The illustration below numbers the probability of re-sight according to the year, so the first re-sight attempt is made in Year 2, and is called <span class="math inline">\(p_{2}\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-1"></span>
<img src="MarkRecapture.png" alt="Diagram of mark-recapture model." width="100%" />
<p class="caption">
Figure 1.1: Diagram of mark-recapture model.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="MarkRecaptureEquations.png" alt="Outcomes and their probabilities of the basic mark-recapture model." width="100%" />
<p class="caption">
Figure 2.1: Outcomes and their probabilities of the basic mark-recapture model.
</p>
</div>
<p>STOP: Look over these probabilities and make sure they make sense.</p>
<p>For example, the probability of surviving three years after marking before being recaptured (or resighted) in the fourth year is given by:</p>
<p><span class="math display">\[
\phi_{1}\phi_{2}\phi_{3}\phi_{4}(1-p_{1})(1-p_{2})(1-p_{3})p_{4}
\]</span></p>
<p>Mark-recapture model selection usually hinges around how to reduce the full number of parameters to something more estimable, for example, by assuming the detection probabilities are the same across capture attempts. Alternatively, you might model survival or capture probabilities as a function of covariates, such as</p>
<p><span class="math display">\[
logit(\phi_{i}) = \beta_{1} + \beta_{2} X_{i}
\]</span></p>
<p>Note that animals can become trap-happy or trap-shy, which means that catching them a second time can be a lot easier or more difficult than catching them the first time. There are dozens and dozens of papers dealing with these kinds of models. You can model either (or both) survival and capture probabilities as a function of time, which means that even with no other parameters, you are looking at four possible models: (<span class="math inline">\(\phi(t),p(t)\)</span>), (<span class="math inline">\(\phi(t),p(.)\)</span>), (<span class="math inline">\(\phi(.),p(t)\)</span>), (<span class="math inline">\(\phi(.),p(.)\)</span>), where I have used <span class="math inline">\(.\)</span> to represent no time dependence.</p>
<p>How would you decide which model was best? We will get into model comparison methods in a few weeks.</p>
<p>McCarthy described two approaches to fitting mark recapture models in JAGS. The first is basically a brute force state-space model in which we explicitly model transitions between each year for each animal. The data required is the full matrix of 0s and 1s recording the capture history for each animal. The second approach is to model the entire capture history (for each animal) at once to work out the likelihood of obtaining that capture history. We will go through both approaches.</p>
</div>
<div id="method-1-brute-force" class="section level2">
<h2><span class="header-section-number">21.3</span> Method #1: Brute force</h2>
<p>The probability of individual <span class="math inline">\(i\)</span> being alive at time <span class="math inline">\(t\)</span> <span class="math inline">\((Z_{i,t}=1)\)</span> conditional on having been alive at time <span class="math inline">\(t-1\)</span> is given by</p>
<p><span class="math display">\[
Z_{i,t} \sim Bern(Z_{i,t-1}\phi)
\]</span> The probability of re-sighting an animal is</p>
<p><span class="math display">\[
Y_{i,t} \sim Bern(Z_{i,t}p)
\]</span></p>
<p>Note that <span class="math inline">\(Z_{i,t}\)</span> is a latent state, knowledge of which is inferred only indirectly through <span class="math inline">\(Y_{i,t}\)</span>, which is the data. I am assuming here constant survival and constant detection probability. The set up looks like</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-3"></span>
<img src="StateSpaceDiagram.png" alt="Transitions in a state-space model" width="100%" />
<p class="caption">
Figure 6.1: Transitions in a state-space model
</p>
</div>
<p>We have a lot of flexibility in modeling capture probabilities. At one extreme, we could model each capture probability separately, and at the other extreme we could assume a constant capture probability for the whole experiment. Somewhere in between these two extremes are models that assume capture probability is drawn from some distribution (this distribution would be governed by ‘hyperparameters’; this is an example of hierarchical modeling which we discussed a few weeks ago), or governed by some covariates (such a time of day, weather, etc.).</p>
<p></p>
</div>
<div id="method-2-modeling-the-entire-capture-history" class="section level2">
<h2><span class="header-section-number">21.4</span> Method #2: Modeling the entire capture history</h2>
<p>The idea behind this is as follows. For the entire period between marking and the last recapture, you know the animal is alive. Between the last resighting and the end of the experiment, you don’t know whether the animal is still alive or not. So we divide up the recapture history into two periods, the first being the period in which we know the animal is alive (from initial marking until <span class="math inline">\(t_{1}\)</span>), and the second in which we do not know whether the animal is alive or dead.</p>
<p>In the first period, you know that the animal survived <span class="math inline">\(t_{1}\)</span> years, and so the detection history of <span class="math inline">\(d\)</span> re-captures and <span class="math inline">\(t_{1}-d\)</span> non-captures:</p>
<p><span class="math display">\[
L_{1} = \phi^{t_{1}}p^{d}(1-p)^{t_{1}-d}
\]</span> Note that we have to include a term for survival probability; the fact that an animal lived for <span class="math inline">\(t_{1}\)</span> years is informative about that parameter.</p>
<p>In the second period, we have to add up all the various possible “paths” of non-detection and/or mortality. In this second period (<span class="math inline">\(t_{2}\)</span> years of non-detection), there are two possibilities: (1) it survived but went undetected for all <span class="math inline">\(t_{2}\)</span> years or (2) it survived and went undetected for <span class="math inline">\(t &lt; t_{2}\)</span> years and then it died. The net result of this is a likelihood that looks like</p>
<p><span class="math display">\[
L_{2} = (1-\phi)\sum_{i=1}^{t_{2}}[\phi(1-p)]^{i-1}+[\phi(1-p)]^{t_{2}}
\]</span> where <span class="math inline">\(\phi\)</span> is the probability of survival and <span class="math inline">\(p\)</span> is the probability of detection. (You may need to write out a few terms to convince yourself of this.)</p>
<p>The joint likelihood of the entire time series is the product of <span class="math inline">\(L_{1}\)</span> and <span class="math inline">\(L_{2}\)</span>.</p>
<p>The advantage to modeling the entire capture history in this way is that you have condensed the data down to three numbers for each mark-recapture history <span class="math inline">\(t_{1}\)</span>, <span class="math inline">\(d\)</span>, and <span class="math inline">\(t_{2}\)</span>, so animals that share these metrics can be combined and the entire dataset, which might be quite large, can be greatly compressed for analysis.</p>
<p><strong>Question</strong>: What would be <span class="math inline">\(t_{1}\)</span>,<span class="math inline">\(t_{2}\)</span>, and <span class="math inline">\(d\)</span> for the capture history 0010110001100000? <details> <summary>Click for Answer</summary> <span style="color: blueviolet;"> In this case, the animal was marked in Year 3, so we disregard the first portion of the capture history as none of these terms contribute to the likelihood. Here, <span class="math inline">\(t_{1}=8\)</span> and in these first 8 years, it was detected <span class="math inline">\(d\)</span>=4 times. There are <span class="math inline">\(t_{2}\)</span>=5 years at the end with no detections, during which time the fate of the animal is unknown. </span> </details></p>
</div>
<div id="what-other-kind-of-models-might-you-fit" class="section level2">
<h2><span class="header-section-number">21.5</span> What other kind of models might you fit</h2>
<p>There are almost an infinite variety of models you might fit to your data. You could build models that include</p>
<ol style="list-style-type: decimal">
<li>year-specific survival rates (either related to year itself, or to some environmental covariates that relate to inter-annual variability in survival)</li>
<li>capture rates that decline with the number of previous captures (once captured, twice shy?)</li>
<li>capture rates that depend on the field biologist setting and checking traps</li>
</ol>
<p>etc.</p>
</div>
<div id="occupancy-modelling" class="section level2">
<h2><span class="header-section-number">21.6</span> Occupancy modelling</h2>
<p>Closely related to mark-recapture models are occupancy models.</p>
<p>Assume you have data from a field sampling program in which the presence or absence of a bird species is recorded along transects at different elevations and tree densities. You have one data point (Y=0 <span class="math inline">\(\rightarrow\)</span> absence, Y=1 <span class="math inline">\(\rightarrow\)</span> presence) for each transect. The basic model in this case would be a logistic model</p>
<p><span class="math display">\[
Y_{i} \sim Bern(p_{i}) \\
logit(p_{i}) = \alpha + \beta* \mbox{Elev}_{i} + \gamma*\mbox{Density}_{i}
\]</span> where I have assumed Elevation and Density as covariates.</p>
<p>Many models for habitat suitability look much like this. Implicitly we have assumed 100<span class="math inline">\(\%\)</span> detection rates, because we assume that our data reflect the true occupancy status.</p>
<p>Let’s say that now we admit the possibility that we have imperfect detection, and sometimes fail to detect the target species when it is present. To manage this scenario, we need to add an “observation model”, and we need some additional information that would allow us to separate true absence from non-detection. What we need are <strong>repeated surveys over some period of time that the population is closed to immigration and emigration</strong>. (This is called a robust sampling design.) These repeat samples allow us to estimate the probability of non-detection when a species is present. We will assume that each transect is surveyed J times each breeding season, and we will assume that the presence of a species in the transect is fixed over that period of time. The observations are now not Bernoulli 0/1 but a Binomial draw that represents the number of times (out of <span class="math inline">\(J\)</span> surveys) that a species was recorded. The resulting model looks something like:</p>
<p><span class="math display">\[
Y_{i} \sim \mbox{Binom}(n=J,p=\mu_{i}) \\
\mu_{i} = Z_{i}*\phi_{i} \\
Z_{i} \sim \mbox{Bern}(p_{i}) \\
\mbox{logit}(p_{i}) = \alpha + \beta*\mbox{Elev}_{i}+\gamma*\mbox{Density}_{i}
\]</span> <span class="math inline">\(Z_{i}\)</span>=True occupancy (0/1)</p>
<p><span class="math inline">\(\phi_{i}\)</span>=Probability of detection</p>
<p><span class="math inline">\(p_{i}\)</span>=Probability of occupancy</p>
<p>Note that we have introduced a latent unmeasured state variable <span class="math inline">\(Z_{i}\)</span> that is analogous to the latent state representing the status of an animal in a mark-recapture context. Also note that if <span class="math inline">\(Y_{i} &gt; 0\)</span>, then <span class="math inline">\(\mu_{i} &gt; 0\)</span>, which means that <span class="math inline">\(Z_{i}\)</span> must equal 1. Transects for which a species was sometimes detected, but not always detected, give us direct information on the probability of detection <span class="math inline">\(\phi_{i}\)</span>. This gives us the ability to estimate the probability of occupancy for transects in which the species was never detected (but which it may occupy).</p>
<p><strong>Side note</strong>: Repeated measurements during which time the population is “closed” is key. There are some attempts to model situations in which only a single survey is performed, but these require a bunch of other assumptions and constraints. By and large, these models require a sampling scheme in which repeated surveys are attempted.</p>
<p>Note that this is basically the site-occupancy model presented by Kery in Chapter 20. We will not have time to get into abundance models, but you can see the basic logic in extending this model to the abundance of animals counted at site <span class="math inline">\(i\)</span> on occasion <span class="math inline">\(j\)</span> (<span class="math inline">\(Y_{ij}\)</span>) as follows:</p>
<p><span class="math display">\[
Y_{ij} \sim \mbox{Binom}(N_{i},p_{ij}) \\
N_{i} \sim \mbox{Pois}(\lambda) \\
\mbox{logit}(p_{ij}) = \mbox{whatever}
\]</span> where the number of animals actually present at site <span class="math inline">\(i\)</span> (<span class="math inline">\(N_{i}\)</span>) is drawn from a Poisson distribution that reflects the overall density of individuals in the landscape.</p>
</div>
<div id="dynamic-state-space-models-for-meta-population-dynamics" class="section level2">
<h2><span class="header-section-number">21.7</span> Dynamic state-space models for meta-population dynamics</h2>
<p>NB: My discussion here follows closely the paper by Royle and Kéry (2007).</p>
<p>In the discussion above, we assumed a totally closed population. <strong>Meta-population models, in which we are interested in colonization and extinction dynamics of sites (or ‘patches’), explicitly include the possibility that a site’s occupancy status might change over time.</strong> In these cases, we assume a sampling strategy in which site occupancy is allowed to change between ‘primary’ sampling periods (often, but not always, between years) but is assumed fixed at secondary sampling intervals (such as within a breeding season). The secondary sampling allows us to estimate the true probability of occupancy in each year, and changes in true occupancy status across years gives us information on the metapopulation dynamics. Note that <strong>if we ignored detection failures, we would probably over-estimate the probabilities of extinction and recolonization</strong>, because a detection history of 101 (found, not found, found) would be interpreted as one extinction event followed by one colonization event. Allowing for detection failures, there emerges a second possibility, which is continuous occupation with a detection failure in year 2.</p>
<p>We model the true occupancy status of site in year (the process model) as</p>
<p><span class="math display">\[
Z_{i,t}|Z_{i,t-1} \sim \mbox{Bern}(Z_{i,t-1}\phi_{t-1}+(1-Z_{i,t-1})\gamma_{t-1})
\]</span> where</p>
<p><span class="math display">\[
\phi_{t-1} = \mbox{probability of patch survival in year t-1} \\
\gamma_{t-1} = \mbox{probability of patch recruitment in year t-1}
\]</span> The observation model for observation <span class="math inline">\(j\)</span> at site <span class="math inline">\(i\)</span> in year <span class="math inline">\(t\)</span> looks like</p>
<p><span class="math display">\[
Y_{j,i,t} \sim \mbox{Bern}(Z_{i,t}p_{t})
\]</span> Royle and Kery make an important point about the difference between finite sample estimators and population estimators (see ‘Finite sample estimation’ section on page 1816). In a conservation context this can be an important distinction. I encourage you to read that section carefully if this is likely to apply to your research.</p>
</div>
<div id="for-more-information-about-this-weeks-topic" class="section level2">
<h2><span class="header-section-number">21.8</span> For more information about this week's topic</h2>
<ul>
<li><a href="https://github.com/hlynch/Bayesian2020/tree/master/_data/BaileyEtAl2013.pdf">Bailey et al. 2014</a></li>
<li><a href="https://github.com/hlynch/Bayesian2020/tree/master/_data/KerySchaubChapter13.pdf">Kery and Schaub Chapter 13</a></li>
<li><a href="https://github.com/hlynch/Bayesian2020/tree/master/_data/MattfeldtEtAl2009.pdf">Mattfeldt et al. 2009</a></li>
<li><a href="https://github.com/hlynch/Bayesian2020/tree/master/_data/Royle2008.pdf">Royle 2008</a></li>
<li><a href="https://github.com/hlynch/Bayesian2020/tree/master/_data/IknayanEtAl2004.pdf">Iknayan et al. 2004</a></li>
<li><a href="https://github.com/hlynch/Bayesian2020/tree/master/_data/KeryRoyle2010.pdf">Kery and Royle 2010</a></li>
<li><a href="https://github.com/hlynch/Bayesian2020/tree/master/_data/Poole2002.pdf">Poole 2002</a></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="week-11-lab.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="week-12-lab.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
